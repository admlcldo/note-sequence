{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('notes', 'r') as file:\n",
    "    notes = [int(x) for x in file.read().split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 10\n",
    "S_LEN = 5 # sequence length\n",
    "D = 12 # number of notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = tf.placeholder(tf.float32, [None, None, D])\n",
    "target = tf.placeholder(tf.float32, [None, None, D])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_hidden = 24\n",
    "cell = tf.contrib.rnn.LSTMCell(num_hidden, state_is_tuple=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val, state = tf.nn.dynamic_rnn(cell, data, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.random_normal([num_hidden, D], stddev=1.0/(num_hidden ** 0.5)))\n",
    "b = tf.Variable(tf.zeros([D]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = tf.tensordot(val, W, axes=[[2], [0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y, labels=target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#optimizer = tf.train.GradientDescentOptimizer(1).minimize(loss)\n",
    "optimizer = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot(x):\n",
    "    v = np.zeros(D)\n",
    "    if x > -1:\n",
    "        v[x] = 1\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lookup = {'': -1, 'C':0, 'Db':1, 'D':2, 'Eb':3, 'E':4, 'F':5, 'Gb':6, 'G':7, 'Ab':8, 'A':9, 'Bb':10, 'B':11}\n",
    "def encode(seq):\n",
    "    return np.array([[one_hot(lookup[x]) for x in seq]])\n",
    "def decode(i):\n",
    "    for n, j in lookup.items():\n",
    "        if j == i:\n",
    "            return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_sample(notes, length):\n",
    "    while True:\n",
    "        start = np.random.randint(0, len(notes)-length-1)\n",
    "        yield np.array([one_hot(x) for x in notes[start:start+length]]), np.array([one_hot(x) for x in notes[start+1:start+length+1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_batch(iterator, batch_size):\n",
    "    while True:\n",
    "        z = np.array([next(single_gen) for _ in range(batch_size)])\n",
    "        yield z[:,0,:,:], z[:,1,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "single_gen = generate_sample(notes, S_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_gen = generate_batch(single_gen, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model restored\n",
      "0 2.08082461977\n",
      "1 2.06976170468\n",
      "2 2.05909202862\n",
      "3 2.05808918262\n",
      "4 2.07373003888\n",
      "5 2.06020962334\n",
      "6 2.06917147732\n",
      "7 2.06910712552\n",
      "8 2.07326132464\n",
      "9 2.07948147321\n",
      "10 2.06137104082\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "SKIP_STEP = 500\n",
    "SKIP_STEP_N = 0\n",
    "NUM_ITERATIONS = 1000000\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    ckpt = tf.train.get_checkpoint_state(os.path.dirname('checkpoints/checkpoint'))\n",
    "    # if that checkpoint exists, restore from checkpoint\n",
    "    if ckpt and ckpt.model_checkpoint_path:\n",
    "        saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "        print('model restored')\n",
    "    else:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        print('model initialized')\n",
    "    \n",
    "    avg_loss = 0\n",
    "    for i in range(NUM_ITERATIONS):\n",
    "\n",
    "        a, b = next(batch_gen)\n",
    "        _ , loss_batch, _ = sess.run([y, loss, optimizer], feed_dict={data:a, target:b})\n",
    "        avg_loss += loss_batch\n",
    "        \n",
    "        if (i+1) % SKIP_STEP == 0:\n",
    "            print(SKIP_STEP_N, avg_loss/SKIP_STEP)\n",
    "            avg_loss = 0\n",
    "            SKIP_STEP_N += 1\n",
    "            saver.save(sess, \"checkpoints/model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded\n",
      "B 0.411546\n",
      "G 0.204688\n",
      "A 0.0978602\n",
      "Bb 0.0769005\n",
      "Gb 0.063734\n",
      "D 0.0586538\n",
      "E 0.0247141\n",
      "C 0.0243797\n",
      "Ab 0.01209\n",
      "Db 0.0118759\n",
      "F 0.0108458\n",
      "Eb 0.00271214\n"
     ]
    }
   ],
   "source": [
    "# look at probability of next notes\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    ckpt = tf.train.get_checkpoint_state(os.path.dirname('checkpoints/checkpoint'))\n",
    "    # if that checkpoint exists, restore from checkpoint\n",
    "    if ckpt and ckpt.model_checkpoint_path:\n",
    "        saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "        print('model loaded')\n",
    "        \n",
    "        test = ['D', 'E', 'Gb', 'G', 'A']\n",
    "        [z] = sess.run([tf.nn.softmax(y)], feed_dict={data:encode(test)})\n",
    "        z = z[0, -1, :]\n",
    "        for i in reversed(z.argsort()):\n",
    "            print(decode(i), z[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded\n",
      "Eb D D G A G D G C C Eb Bb Bb Eb F C Eb Eb G C D C F Eb G Eb G B B D Gb A G Gb C E E C A D Eb Eb Eb Eb G C G C D G G G A G B Eb D G C G B D G Gb A G A C G B D G Gb E Gb D Gb A D Db B A Db D Db B Db D Db D Db D Db D Eb Gb E Eb D E Gb\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    \n",
    "    ckpt = tf.train.get_checkpoint_state(os.path.dirname('checkpoints/checkpoint'))\n",
    "    # if that checkpoint exists, restore from checkpoint\n",
    "    if ckpt and ckpt.model_checkpoint_path:\n",
    "        saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "        print('model loaded')\n",
    "        \n",
    "        test = ['Eb']\n",
    "        for _ in range(100):\n",
    "            [z] = sess.run([tf.nn.softmax(y)], feed_dict={data:encode(test)})\n",
    "            z = z[0, -1, :]\n",
    "            next_note = np.random.choice(D, p=z)\n",
    "            test.append(decode(next_note))\n",
    "        print(' '.join(test))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import mido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mid = mido.MidiFile()\n",
    "track = mido.MidiTrack()\n",
    "mid.tracks.append(track)\n",
    "delta = 300\n",
    "for n in [lookup[x] + 60 for x in test]:\n",
    "    track.append(mido.Message('note_on', note=n, velocity=64, time=0))\n",
    "    track.append(mido.Message('note_on', note=n, velocity=0, time=delta))\n",
    "mid.save('generated.midi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mid = mido.MidiFile()\n",
    "track = mido.MidiTrack()\n",
    "mid.tracks.append(track)\n",
    "delta = 300\n",
    "for _ in test:\n",
    "    n = np.random.randint(12) + 60\n",
    "    track.append(mido.Message('note_on', note=n, velocity=64, time=0))\n",
    "    track.append(mido.Message('note_on', note=n, velocity=0, time=delta))\n",
    "mid.save('random.midi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [tensorflow]",
   "language": "python",
   "name": "Python [tensorflow]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
